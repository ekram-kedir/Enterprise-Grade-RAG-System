{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "rpath = os.path.abspath('./..')\n",
    "if rpath not in sys.path:\n",
    "    sys.path.insert(0, rpath)\n",
    "    \n",
    "from source.retriever import create_retriever\n",
    "from source.generator import generator\n",
    "from source.loader import data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Specify the path for the .env file\n",
    "dotenv_path = './../../.env'  # Replace with the actual path to your .env file\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Now you can access the environment variables using os.environ\n",
    "# import os\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(os.getenv(\"VECTORDB_MODEL\"))\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"VECTORDB_MODEL\"] = \"gpt-3.5-turbo\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1757, which is longer than the specified 500\n",
      "Created a chunk of size 1320, which is longer than the specified 500\n",
      "Created a chunk of size 859, which is longer than the specified 500\n",
      "Created a chunk of size 517, which is longer than the specified 500\n",
      "Created a chunk of size 1345, which is longer than the specified 500\n",
      "Created a chunk of size 1988, which is longer than the specified 500\n",
      "Created a chunk of size 851, which is longer than the specified 500\n",
      "Created a chunk of size 1221, which is longer than the specified 500\n",
      "Created a chunk of size 852, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded weaviate is already listening on port 8079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/opt/homebrew/lib/python3.10/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "chunks =  data_loader(file_path=\"./../prompts/challenge_document.txt\")\n",
    "retriever = create_retriever(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Weaviate', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.weaviate.Weaviate object at 0x13966b8e0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your .txt file\n",
    "file_path = '../prompts/generate_prompt.txt'\n",
    "\n",
    "# Open the file in read mode\n",
    "with open(file_path, 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    file_contents = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = generator(retriever, file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Weaviate', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.weaviate.Weaviate object at 0x13966b8e0>),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are a prompt generator which generate a list of prompts paired with their ground truth for the user\\nquestion Use the following pieces of retrieved context to generate both the question and the answer. \\nIf you don't know the answer, just say that you don't know but if the answer is already in the document give the answer. \\nUse two sentences maximum and keep the answer concise. return a list of 5 prompts with their ground truth. \\nreturn in json format\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x138245cc0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x13820e4d0>, temperature=0.0, openai_api_key='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', openai_proxy='')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/opt/homebrew/lib/python3.10/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/opt/homebrew/lib/python3.10/site-packages/langchain_community/chat_models/openai.py:458: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/opt/homebrew/lib/python3.10/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "generated_prompts = rag_chain.invoke(\"generate for me a questions that will help me understand the challenge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"prompt\": \"What are the key performance indicators for understanding the challenge?\",\\n    \"ground_truth\": \"Understanding week’s challenge, Understanding the prompt engineering\"\\n  },\\n  {\\n    \"prompt\": \"What are some techniques to improve RAG in RAG?\",\\n    \"ground_truth\": \"Techniques to improving R (Retrievers) in RAG (Emitnan)\"\\n  },\\n  {\\n    \"prompt\": \"What are some key areas of knowledge acquisition for prompt engineering?\",\\n    \"ground_truth\": \"Understanding of Language Models, Insights into Automated Evaluation Data Generation, ELO Rating System and its Applications, Prompt Optimization Strategies, Industry Best Practices\"\\n  },\\n  {\\n    \"prompt\": \"Which companies are doing something similar to this project?\",\\n    \"ground_truth\": \"AI Prompt Generator (promptlygenerated.com)\"\\n  },\\n  {\\n    \"prompt\": \"What are the tasks involved in developing the prompt generation system?\",\\n    \"ground_truth\": \"Build and Refine Prompt Generation System, Develop Automatic Evaluation Data Generation System, Implement Prompt Testing and Evaluation Mechanism\"\\n  }\\n]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'What are the key performance indicators for understanding the challenge?',\n",
       "  'ground_truth': 'Understanding week’s challenge, Understanding the prompt engineering'},\n",
       " {'prompt': 'What are some techniques to improve RAG in RAG?',\n",
       "  'ground_truth': 'Techniques to improving R (Retrievers) in RAG (Emitnan)'},\n",
       " {'prompt': 'What are some key areas of knowledge acquisition for prompt engineering?',\n",
       "  'ground_truth': 'Understanding of Language Models, Insights into Automated Evaluation Data Generation, ELO Rating System and its Applications, Prompt Optimization Strategies, Industry Best Practices'},\n",
       " {'prompt': 'Which companies are doing something similar to this project?',\n",
       "  'ground_truth': 'AI Prompt Generator (promptlygenerated.com)'},\n",
       " {'prompt': 'What are the tasks involved in developing the prompt generation system?',\n",
       "  'ground_truth': 'Build and Refine Prompt Generation System, Develop Automatic Evaluation Data Generation System, Implement Prompt Testing and Evaluation Mechanism'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_prompts = json.loads(generated_prompts)\n",
    "generated_prompts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
